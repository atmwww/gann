{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cannot disclose confidential data. will prepare a data soon from public source\n",
    "data = pd.read_csv('data.csv',index_col=0,header=None,names=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert index to datetime\n",
    "data.index = pd.to_datetime(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For simplificity and limited resources and time I have, I work on daily data for now. The model could be extended to work with intraday data.\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "customBd=CustomBusinessDay(calendar=USFederalHolidayCalendar())\n",
    "dailyData = data.resample(customBd, how={'price': 'last'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dta = dailyData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(dta.index,dta.price)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there is na, inf or -inf in data set.\n",
    "len(dta) != len(dta.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dta)!=len(dta.replace([np.inf, -np.inf], np.nan).dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#replace all na, inf or -inf data with the data of previous date\n",
    "for i in range(len(dta.price)):\n",
    "    if np.isnan(dta.price[i]) or dta.price[i] == np.inf or dta.price[i] == -np.inf:\n",
    "        if i>0:\n",
    "            dta.price[i]=dta.price[i-1]            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to implement a Genetic Algorithm + Neural Network (identification of multistationary models) to predict future prices. The idea is rather than trying to identify a global model, to identify different local models(e.g. within a day or a regime). \n",
    "The algorithm has two components: (1) GA for a classifier and selector on different local models. (2) Neural Network is for predication of local time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. GA is based on domain indicators from techinical analysis to identify local models. You can add meaningful domain indicators based on your research and your data structure.\n",
    "Here due to the limited time and resources I have, I only implement common domain indicators: just crossed a valley;just surmounted a peak; too many sales or purchases; bull or bear period;bull bear period has finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaIns = pd.DataFrame(index=dta.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#monthly difference of averages (doa)\n",
    "meanF = 20\n",
    "ma = pd.rolling_mean(dta,meanF)\n",
    "doa = dta - ma\n",
    "\n",
    "#just crossed a valley\n",
    "gaIns['cVal'] = (doa.shift(1)<0) & (doa>0)\n",
    "#just surmounted a peak\n",
    "gaIns['sPeak'] = (doa.shift(1)>0) & (doa<0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3 week relative strength index\n",
    "rsiF = 15\n",
    "pos = (dta - dta.shift(1))/dta\n",
    "pos[pos<0] = 0\n",
    "neg = (dta.shift(1)-dta)/dta\n",
    "neg[neg<0] = 0\n",
    "rsi = 1/(1+pd.rolling_mean(neg,rsiF)/pd.rolling_mean(pos,rsiF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "TODO.some work could be done to more careful deal with possible nan, inf or -inf in pos, neg and rsi dataset.\n",
    "But it won't stop the model running successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#too many sales vs purchases\n",
    "gaIns['sp'] = rsi < 0.3\n",
    "gaIns['ps'] = rsi > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bull bear period\n",
    "bbPeriod = 5 \n",
    "localM = 3\n",
    "lMin = pd.rolling_min(dta,localM)\n",
    "lMax = pd.rolling_max(dta,localM)\n",
    "\n",
    "def isBull(L):\n",
    "    return all(x<y for x, y in zip(L, L[1:]))\n",
    "\n",
    "def isBear(L):\n",
    "    return all(x>y for x, y in zip(L, L[1:]))\n",
    "\n",
    "up = pd.rolling_apply(lMin,bbPeriod,lambda x: isBull(x))==1\n",
    "gaIns['up'] = up \n",
    "dw = pd.rolling_apply(lMax,bbPeriod,lambda x: isBear(x))==1\n",
    "gaIns['dw'] = dw \n",
    "\n",
    "#bull bear period has finished\n",
    "gaIns['upEnd'] = up.shift(1) & (~up)\n",
    "gaIns['dwEnd'] = dw.shift(1) & (~dw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Neural network for local models. Similar you can modify and add inputs based on your research. Here I only implement common inputs for local models are: monthly difference of averages (normalized with MA 30);3 weeks rate of change (average with MA3);3 week relative strength index;monthly standard Deviation of relative price( averaged with MA10);latest 5 prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annIns = pd.DataFrame(index=dta.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#monthly difference of averages (normalized with MA 30)\n",
    "annIns['normDoa'] = doa/ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 weeks rate of change (average with MA3)\n",
    "rocF = 15\n",
    "roc = (dta-dta.shift(rocF))/dta.shift(rocF)\n",
    "maRocF = 3\n",
    "annIns['maRoc'] = pd.rolling_mean(roc,maRocF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3 week relative strength index\n",
    "annIns['rsi'] = rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#monthly standard Deviation of relative price( averaged with MA10)\n",
    "stdF = 30\n",
    "stdMaF = 10\n",
    "rollStd = pd.rolling_std(dta,stdF)\n",
    "annIns['rollStdMa'] = pd.rolling_mean(rollStd,stdMaF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#latest 5 prices\n",
    "annIns['DL0'] = dta\n",
    "annIns['DL1'] = dta.shift(1)\n",
    "annIns['DL2'] = dta.shift(2)\n",
    "annIns['DL3'] = dta.shift(3)\n",
    "annIns['DL4'] = dta.shift(4)\n",
    "annIns['DL5'] = dta.shift(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neural network could have multiple outputs. Actually outputing consecutive 3 prices variaion slopes is better than 1. \n",
    "# But due to limited time and resource, here I implemente one output: relative price change.\n",
    "annOut = (dta-dta.shift(1))/dta.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#divide data into train and test dataset\n",
    "# proportion of training data\n",
    "p = 0.1 \n",
    "#I use only 10%data to train the algorithm due to my pc cannot handle more data.\n",
    "#which means I used 10% data to predict 80% data.I am not surprised the result is not very good.\n",
    "#if you have faster pc, please feel free to adjust p = 0.8 as usual.\n",
    "split = int(len(dta.index)*p)\n",
    "n = 28 #skip some early data due to rolling calcualtion.\n",
    "\n",
    "gasTrain = gaIns[n:split]\n",
    "annsTrain = annIns[n:split]\n",
    "annOutTrain = annOut[n:split]\n",
    "\n",
    "gasTest = gaIns[split:]\n",
    "annsTest = annIns[split:]\n",
    "annOutTest = annOut[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Back-Propagation Neural Networks\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# my sigmoid function is tanha \n",
    "def sigmoid(x):\n",
    "    return np.tanh(x)\n",
    "# derivative of our sigmoid function, in terms of the output (i.e. y)\n",
    "def dsigmoid(y):\n",
    "    return 1.0 - y*y\n",
    "# 1 hidden layer artifical neural network class\n",
    "class ANN:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        # number of input, hidden, and output nodes\n",
    "        self.ni = ni + 1 # +1 for bias node\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "\n",
    "        # activations for nodes\n",
    "        self.ai = np.ones(self.ni)\n",
    "        self.ah = np.ones(self.nh)\n",
    "        self.ao = np.ones(self.no)\n",
    "        \n",
    "        # create weights and set them to small random vaules [-0.2,0.2]\n",
    "        mm = 0.2\n",
    "        self.wi = np.random.random((self.ni, self.nh))*2*mm-mm\n",
    "        self.wo = np.random.random((self.nh, self.no))*2*mm-mm\n",
    "\n",
    "        # last change in weights for momentum   \n",
    "        self.ci = np.zeros((self.ni, self.nh))\n",
    "        self.co = np.zeros((self.nh, self.no))\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        if len(inputs) != self.ni-1:\n",
    "            raise ValueError('wrong number of inputs')\n",
    "\n",
    "        # input activations\n",
    "        for i in range(self.ni-1):\n",
    "            self.ai[i] = inputs[i]\n",
    "\n",
    "        # hidden activations\n",
    "        for j in range(self.nh):\n",
    "            sum = 0.0\n",
    "            for i in range(self.ni):\n",
    "                sum = sum + self.ai[i] * self.wi[i][j]\n",
    "            self.ah[j] = sigmoid(sum)\n",
    "\n",
    "        # output activations\n",
    "        for k in range(self.no):\n",
    "            sum = 0.0\n",
    "            for j in range(self.nh):\n",
    "                sum = sum + self.ah[j] * self.wo[j][k]\n",
    "            self.ao[k] = sigmoid(sum)\n",
    "\n",
    "        return self.ao[:]\n",
    "\n",
    "\n",
    "    def backPropagate(self, targets, N, M):\n",
    "        if len(targets) != self.no:\n",
    "            raise ValueError('wrong number of target values')\n",
    "\n",
    "        # calculate error terms for output\n",
    "        output_deltas = np.zeros(self.no)\n",
    "        for k in range(self.no):\n",
    "            error = targets[k]-self.ao[k]\n",
    "            output_deltas[k] = dsigmoid(self.ao[k]) * error\n",
    "\n",
    "        # calculate error terms for hidden\n",
    "        hidden_deltas = np.zeros(self.nh)\n",
    "        for j in range(self.nh):\n",
    "            error = 0.0\n",
    "            for k in range(self.no):\n",
    "                error = error + output_deltas[k]*self.wo[j][k]\n",
    "            hidden_deltas[j] = dsigmoid(self.ah[j]) * error\n",
    "\n",
    "        # update output weights\n",
    "        for j in range(self.nh):\n",
    "            for k in range(self.no):\n",
    "                change = output_deltas[k]*self.ah[j]\n",
    "                self.wo[j][k] = self.wo[j][k] + N*change + M*self.co[j][k]\n",
    "                self.co[j][k] = change\n",
    "\n",
    "        # update input weights\n",
    "        for i in range(self.ni):\n",
    "            for j in range(self.nh):\n",
    "                change = hidden_deltas[j]*self.ai[i]\n",
    "                self.wi[i][j] = self.wi[i][j] + N*change + M*self.ci[i][j]\n",
    "                self.ci[i][j] = change\n",
    "\n",
    "        # calculate error\n",
    "        error = 0.0\n",
    "        for k in range(len(targets)):\n",
    "            error = error + 0.5*(targets[k]-self.ao[k])**2\n",
    "        return error\n",
    "\n",
    "\n",
    "    def pred(self, x):\n",
    "        predY = []\n",
    "        for j in range(x.shape[0]):\n",
    "            predY.append(self.feedforward(x[j]))\n",
    "        return predY\n",
    "        \n",
    "\n",
    "    def train(self, x, y, iterations=1000, N=0.5, M=0.1):\n",
    "        # N: learning rate\n",
    "        # M: momentum factor\n",
    "        if x.shape[0] != y.shape[0]:\n",
    "            raise ValueError('x,y shape mismatches')\n",
    "            \n",
    "        for i in range(iterations):\n",
    "            error = 0.0\n",
    "            for j in range(x.shape[0]):\n",
    "                inputs = x[j]\n",
    "                targets = y[j]\n",
    "                self.feedforward(inputs)\n",
    "                error = error + self.backPropagate(targets, N, M)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate and momentun factor could be optimized by cross validation. I did not do that due to limited time and resource I have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "numSol = gasTrain.shape[1]\n",
    "\n",
    "def costf(sol):\n",
    "    global annsTrain \n",
    "    global rpsTrain \n",
    "    global gasTrain\n",
    "    gaTrain = gasTrain.values == True\n",
    "    xTrain = annsTrain.values\n",
    "    yTrain = annOutTrain.values\n",
    "    for i in range(len(sol)):\n",
    "        if xTrain.shape[0] != gaTrain.shape[0] or yTrain.shape[0] != gaTrain.shape[0]:\n",
    "            raise ValueError('x,y shape mismatches')\n",
    "        \n",
    "        if sol[i] == 1:   \n",
    "            xTrain = xTrain[gaTrain[:,i]]\n",
    "            yTrain = yTrain[gaTrain[:,i]]\n",
    "            gaTrain = gaTrain[gaTrain[:,i]]\n",
    "        elif sol[i] == 0:\n",
    "            xTrain = xTrain[[not(x) for x in gaTrain[:,i]]]\n",
    "            yTrain = yTrain[[not(x) for x in gaTrain[:,i]]]\n",
    "            gaTrain = gaTrain[[not(x) for x in gaTrain[:,i]]]\n",
    "    if len(xTrain) ==0 or len(yTrain) ==0:\n",
    "        error = np.inf\n",
    "    else:\n",
    "        numIns = xTrain.shape[1]\n",
    "        numOut = yTrain.shape[1]\n",
    "        nn = ANN(numIns, max(numIns,numOut)+1, numOut)\n",
    "\n",
    "        # train it with some patterns\n",
    "        error = nn.train(xTrain,yTrain)\n",
    "        \n",
    "    return error\n",
    "\n",
    "def geneticoptimize(domain,costf,popsize=50,maxiter=1000,step=1,\n",
    "                    mutprod=0.2,elite=0.2):\n",
    "    # Mutation Operation\n",
    "    def mutate(vec):\n",
    "        i=random.randint(0,len(domain)-1)\n",
    "        if vec[i]==domain[i][0]:\n",
    "            return vec[0:i]+[vec[i]+step]+vec[i+1:] \n",
    "        elif vec[i]==domain[i][1]:\n",
    "            return vec[0:i]+[vec[i]-step]+vec[i+1:]\n",
    "        elif random.random()<0.5:\n",
    "            return vec[0:i]+[vec[i]-step]+vec[i+1:] \n",
    "        else:\n",
    "            return vec[0:i]+[vec[i]+step]+vec[i+1:]\n",
    "        #return vec\n",
    "    # Crossover Operation\n",
    "    def crossover(r1,r2):\n",
    "        i=random.randint(1,len(domain)-2)\n",
    "        return r1[0:i]+r2[i:]\n",
    "\n",
    "    # Build the initial population\n",
    "    pop=[]\n",
    "    for i in range(popsize):\n",
    "        vec=[random.randint(domain[i][0],domain[i][1]) \n",
    "            for i in range(len(domain))]\n",
    "        pop.append(vec)\n",
    "    # How many winners from each generation?\n",
    "    topelite=int(elite*popsize)\n",
    "    scores=[(costf(v),v) for v in pop[0:topelite]]\n",
    "  \n",
    "    # Main loop \n",
    "    for i in range(maxiter):\n",
    "        for v in pop[topelite:]:\n",
    "            scores.append((costf(v),v))\n",
    "        scores.sort()\n",
    "        #print('bs',scores)\n",
    "        ranked=[v for (s,v) in scores]\n",
    "    \n",
    "        # Start with the pure winners\n",
    "        pop=ranked[0:topelite]\n",
    "        scores = scores[0:topelite]\n",
    "        # Add mutated and bred forms of the winners\n",
    "        while len(pop)<popsize:\n",
    "            if np.random.rand()<0.2:#mutprob:\n",
    "                # Mutation\n",
    "                c=random.randint(0,topelite)\n",
    "                pop.append(mutate(ranked[c]))\n",
    "            else:      \n",
    "                # Crossover\n",
    "                c1=random.randint(0,topelite)\n",
    "                c2=random.randint(0,topelite)\n",
    "                pop.append(crossover(ranked[c1],ranked[c2]))\n",
    "        # Print current best scores\n",
    "        print('bs',scores)\n",
    "\n",
    "    return scores          \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bs', [(inf, [0, 0, 1, 1, 0, 1, 0, 2]), (inf, [0, 0, 2, 2, 1, 0, 2, 0])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 1, 0, 2]), (inf, [0, 0, 1, 1, 0, 1, 0, 2])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 1, 0, 2]), (inf, [0, 0, 1, 1, 0, 1, 0, 2])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 2]), (inf, [0, 0, 1, 1, 0, 1, 0, 2])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 2]), (inf, [0, 0, 1, 1, 0, 1, 0, 2])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 2]), (inf, [0, 0, 1, 1, 0, 0, 0, 2])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 1, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 0, 1, 0, 0, 0, 1]), (inf, [0, 0, 1, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 0, 1, 0, 0, 0, 1]), (inf, [0, 0, 0, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 0, 1, 0, 0, 0, 1]), (inf, [0, 0, 0, 1, 0, 0, 0, 1])])\n",
      "('bs', [(inf, [0, 0, 0, 1, 0, 0, 0, 1]), (inf, [0, 0, 0, 1, 0, 0, 0, 1])])"
     ]
    }
   ],
   "source": [
    "#main function for the GA+neural network model\n",
    "domain = [(0,2)]*numSol\n",
    "scores = geneticoptimize(domain,costf,10) \n",
    "#I use 10 popsize to speed up the algorithm and sacrifice accuracy of results. Please increase popsize to get more meaningful results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Actually the simiplified algorithm has one drawback that the best solutions may not cover all dataset.\n",
    "#So it makes more sense to check other top solutions as well to make sure cover all dataset.\n",
    "#One thing about the algorithm could be improved to keep a set of solutions that could completely cover all dataset.\n",
    "\n",
    "#Predict test data for the best solution for example.\n",
    "sol = scores[0][1]\n",
    "    \n",
    "global annsTrain \n",
    "global rpsTrain \n",
    "global gasTrain\n",
    "gaTrain = gasTrain.values == True\n",
    "xTrain = annsTrain.values\n",
    "yTrain = annOutTrain.values\n",
    "\n",
    "for i in range(len(sol)):\n",
    "    if xTrain.shape[0] != gaTrain.shape[0] or yTrain.shape[0] != gaTrain.shape[0]:\n",
    "        raise ValueError('x,y shape mismatches')\n",
    "        \n",
    "    if sol[i] == 1:   \n",
    "        xTrain = xTrain[gaTrain[:,i]]\n",
    "        yTrain = yTrain[gaTrain[:,i]]\n",
    "        gaTrain = gaTrain[gaTrain[:,i]]\n",
    "    elif sol[i] == 0:\n",
    "        xTrain = xTrain[[not(x) for x in gaTrain[:,i]]]\n",
    "        yTrain = yTrain[[not(x) for x in gaTrain[:,i]]]\n",
    "        gaTrain = gaTrain[[not(x) for x in gaTrain[:,i]]]\n",
    "\n",
    "numIns = xTrain.shape[1]\n",
    "numOut = yTrain.shape[1]\n",
    "nn = ANN(numIns, max(numIns,numOut)+1, numOut)\n",
    "\n",
    "# train it with some patterns\n",
    "for i in range(10):\n",
    "    error = nn.train(xTrain,yTrain)\n",
    "    print('error',error)   \n",
    "\n",
    "global annsTest\n",
    "global rpsTest \n",
    "global gasTest\n",
    "gaTest = gasTest.values == True\n",
    "xTest= annsTest.values\n",
    "yTest = annOutTest.values\n",
    "indexTest = gasTest.index\n",
    "    \n",
    "for i in range(len(sol)):\n",
    "    if xTest.shape[0] != gaTest.shape[0]:\n",
    "        raise ValueError('x,y shape mismatches')\n",
    "        \n",
    "    if sol[i] == 1:   \n",
    "        xTest = xTest[gaTest[:,i]]\n",
    "        yTest = yTest[gaTest[:,i]]\n",
    "        indexTest = indexTest[gaTest[:,i]]\n",
    "        gaTest = gaTest[gaTest[:,i]]\n",
    "    elif sol[i] == 0:\n",
    "        xTest = xTest[[not(x) for x in gaTest[:,i]]]\n",
    "        yTest= yTest[[not(x) for x in gaTest[:,i]]]\n",
    "        indexTest = indexTest[[not(x) for x in gaTest[:,i]]]\n",
    "        gaTest = gaTest[[not(x) for x in gaTest[:,i]]]\n",
    "\n",
    "# pred it \n",
    "yPred = nn.pred(xTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(indexTest,yTest,indexTest,yPred)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
